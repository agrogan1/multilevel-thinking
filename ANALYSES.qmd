---
title: "Analyses"
author: "Andy Grogan-Kaylor"
editor: source
---

# Setup

```{r}

library(Statamarkdown)

library(lme4) 

library(JuliaCall)

# julia_setup(JULIA_HOME = "/Applications/Julia-1.10.app/Contents/Resources/julia/bin")

# julia_setup(JULIA_HOME = "C:/Users/agrogan/AppData/Local/Programs/Julia-1.10.2/bin/")

```

# Four Level Model

## Stata

```{stata, collectcode=TRUE}

use "./simulate-and-analyze-multilevel-data/fourlevel.dta", clear

```

```{stata, collectcode=TRUE}

mixed outcome || UNregion: || country: || family:

```

```{stata, collectcode=TRUE}

mixed outcome t warmth physical_punishment i.identity i.intervention HDI || UNregion: || country: || id:
  
```

## R

```{r}

library(haven)

df4 <- read_dta("./simulate-and-analyze-multilevel-data/fourlevel.dta")

```

```{r}

dfL$identity <- factor(dfL$identity)

dfL$intervention <- factor(dfL$intervention)

```

: {.callout-caution collapse="false"}
`lme4` does not directly provide p values in results, because of some disagreement over exactly how these p values should be calculated. Therefore, in this Appendix, I also call library `lmerTest` to provide p values for `lme4` results.
:::

::: {.callout-tip}
R prefers to use scientific notation when possible. I find that the use of scientific notation can be confusing in reading results. I turn off scientific notation by setting a penalty for its use:  `options(scipen = 999)`.  
:::


```{r}

library(lme4) 

library(lmerTest)

options(scipen = 999) 

fit4A <- lmer(outcome ~  (1 | UNregion/country/id),
             data = df4)

summary(fit4A)

```

```{r}

fit4B <- lmer(outcome ~ t + warmth + physical_punishment + 
                identity + intervention + HDI + 
                (1 | UNregion/country/id),
              data = df4)

summary(fit4B)

```



# Cross Classified Model

