{
  "hash": "7504f658714dd95d6ede33e96b377088",
  "result": {
    "markdown": "# The Cross Sectional Multilevel Model\n\n> \"Mathematical Science shows us what is. It is the language of unseen relations between things. But to use & apply that language we must be able fully to appreciate, to feel, to seize, the unseen, the unconscious. Imagination too shows us what is, the is that is beyond the senses.” [@Lovelace1992]\n\n\n\n\n::: {.cell}\n\n:::\n\n\n\n\nI begin this chapter by introducing two key concepts: multilevel models can improve our estimation of p values; multilevel models can improve our estimation of $\\beta$ coefficients.\n\nIn these sections I make some initial use of the Stata syntax for regression `regress y x z`, and the Stata syntax for multilevel models, `mixed y x z || groupid:`.\n\nAfter introducing these two key concepts of multilevel modeling, I then begin a more in depth exploration of the equations and concepts and statistical syntax of the cross sectional multilevel model.\n\n## Estimating Standard Errors And p Values {#sec-pvalues}\n\n### Introduction\n\nIf the data are grouped, nested, or clustered, then this aspect of the structure of the data needs to be accounted for. @Bland1994 describe a simulation in which grouped data are artificially generated according to the following procedure.\n\n> \"The data were generated from random numbers, and there is no relation between X and Y at all. Firstly, values of X and Y were generated for each 'subject,' then a further random number was added to make the individual observation.\" [@Bland1994]\n\n\n\n\n::: {.cell}\n\n:::\n\n\n\n\nThe graph below illustrates the process of simulating the data.\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Simulated Clustered Data](cross-sectional_files/figure-pdf/fig-simulatedclustereddata-1.pdf){#fig-simulatedclustereddata}\n:::\n:::\n\n\n\n\n### Compare OLS and MLM\n\nAn analysis that is not aware of the grouped nature of the data will give biased results, will mis-estimate standard errors, and importantly, will often attribute statistical significance to some of the independent variables when this is not appropriate [@Raudenbush2002; @Bland1994]. \n\nIn the example below, we compare a simple ordinary least squares analysis of the data with a multilevel model that accounts for the clustered nature of the data.\n\nThe Stata syntax that we use for each analysis is:\n\n* OLS: `regress y x`\n* Multilevel Model: `mixed y x || group:`\n\n\n\n\n\n|                        | OLS   |    | MLM    |    |\n|------------------------|-------|----|--------|----|\n| x                      | 1.046 | ** | 0.039  |    |\n| Intercept              | 4.488 |    | 97.005 | ** |\n| var(_cons)             |       |    | 74.523 |    |\n| var(e)                 |       |    | 0.594  |    |\n| Number of observations | 25    |    |        |    |\n** p<.01, * p<.05\n\n\n\n\nWe see that in the ordinary least squares analysis, the independent variable is judged to have a statistically significant association with the dependent variable. The more appropriate multilevel model finds that in fact the independent variable $x$ is *not* associated with $y$. Thus, the multilevel model provides more accurate results than OLS in the presence of clustered data.\n\n## Multilevel Structure {#sec-multilevelstructure}\n\nAssociations between two variables can be *very different* (or even *reversed*) depending upon whether or not the analysis is \"aware\" of the grouped, nested, or clustered nature of the data [@Gelman2007]. In the example presented here, the groups are countries, but could as easily be neighborhoods, communities, or schools.\n\n> For teaching purposes, I use an example with very few clusters, although it would be more appropriate to apply multilevel analysis to an example with many more clusters e.g. ($N_\\text{clusters} >= 30$)\n\nA model that is \"aware\" of the clustered nature of the data may provide very different--likely better--substantive conclusions than a model that is not aware of the clustered nature of the data. \n\nI use some data simulated for this particular example.\n\n\n\n\n::: {.cell}\n\n:::\n\n\n\n\n### Graphs\n\n#### A \"Naive\" Graph \n\nThis \"naive\" graph is unaware of the grouped nature of the data. Notice that the overall regression line slopes downward, even though there is some suggestion that *within each group* the regression lines may slope upward.\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![A 'Naive' Graph](cross-sectional_files/figure-pdf/fig-naive-1.pdf){#fig-naive}\n:::\n:::\n\n\n\n\n#### An \"Aware\" Graph \n\nThis \"aware\" graph is aware of the grouped nature of the data. The graph is \"aware\" of the grouped or clustered nature of the data, and provides indication that the regression lines *when accounting for group* slope upward.\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![An 'Aware' Graph](cross-sectional_files/figure-pdf/fig-aware-1.pdf){#fig-aware}\n:::\n:::\n\n\n\n\n### Regressions\n\n#### A \"Naive\" OLS Analysis vs. An \"Aware\" MLM Analysis\n\nThe Stata syntax that we use for these analyses is: \n\n* OLS: `regress y x` \n* Multilevel Model: `mixed y x || country:`\n\nThe OLS model with only *x* as a covariate is not aware of the grouped structure of the data, and the coefficient for *x* in the OLS model reflects this. The coefficient for *x* in the OLS model is *negative*, and statistically significant.\n\nThe multilevel model is aware of the grouped structure of the data, and the coefficient for *x* in the multilevel model reflects this. The coefficient for *x* in the multilevel model is *positive*, and statistically significant.\n\n\n\n\n\n|                        | OLS    |    | MLM     |    |\n|------------------------|--------|----|---------|----|\n| x                      | -0.775 | ** | 1.038   | ** |\n| Intercept              | 57.133 | ** | 29.029  | ** |\n| var(_cons)             |        |    | 276.867 |    |\n| var(e)                 |        |    | 0.916   |    |\n| Number of observations | 30     |    |         |    |\n** p<.01, * p<.05\n\n\n\n\n### A Thought Experiment\n\nWhen might a situation like this arise in practice? This is surprisingly difficult to think through. \n\nImagine that *x* is a protective factor, or an intervention or treatment. Imagine that *y* is a desirable outcome, like improved mental health or psychological well being.\n\nNow imagine that residents of countries provide more of the protective factor or more of the intervention in situations where there are lower levels of the desirable outcome. If one thinks about it, this is a very plausible situation. \n\n> A naive analysis that was unaware of the grouped nature of the data would therefore misconstrue the results, suggesting that the intervention was harmful, when it was in fact helpful.\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![A Heuristic Example](cross-sectional_files/figure-pdf/unnamed-chunk-9-1.pdf)\n:::\n:::\n\n\n\n\nThe idea that group level and individual level relationships must be the same [@FIREBAUGH20014023] has been termed the \"ecological fallacy\".\n\nThese data are constructed to provide this kind of extreme example, but it easy to see how multilevel thinking, and multilevel analysis may provide better answers than one would get if one ignored the grouped nature of the data.\n\n## The Equation\n\nThe equation for the multilevel model can be written in several ways: as multiple levels of equations; or as a single equation. The advantage of having multiple levels of equations is that these multiple equations make clear the multiple levels of the data, and thus conform to an initial understanding of how a multilevel model should be estimated. However, *results* from multiple levels of equations quickly become difficult to interpret, and thus, I will not spend a great deal of time on discussing empirical results of the two level formulation. Whether multiple levels of equations, or a single equation are employed, the numerical results are equivalent.s\n\n### Two Levels of Equations\n\nI start with two levels of equations: Level 1 at the level of the individual; and Level 2 at the level of the country.\n\n#### Level 1 (Individuals)\n\n$$y_{ij} = \\beta_{0j} + \\beta_{1j} x_{ij} + \\beta_{2j} z_{ij} + e_{ij}$$ {#eq-MLM1}\n\n#### Level 2 (Countries)\n\n$$\\beta_{0j} = \\gamma_{00} +\\gamma_{01} w_j + u_{0j}$$ {#eq-MLM2}\n\n$$\\beta_{1j} = \\gamma_{10} + u_{1j}$$\n\n$$\\beta_{2j} = \\gamma_{20}$$\n\n$$\\beta_{3j} = \\gamma_{30}$$\n\nHere $y_{ij}$ is the dependent variable, or outcome for the model. We note that the $ij$ subscripts indicate that this is outcome $y$ for individual $i$ in country $j$. Note that the outcome is at Level 1, or the level of individuals. $\\beta_{0j}$ is a regression intercept, and the other $\\beta$'s[^beta:] are regression slope parameters. $x_{ij}$ and $z_{ij}$ are independent variables and $t_{ij}$ is an independent variable indicating the time at which different data points are measured. I note that in this discussion I am *not* considering a model in which there are repeated observations on the same individuals, although the multilevel model is certainly extensible to such cases. $u_{0j}$ is a random intercept for the $\\beta_{0j}$ term, and $u_{1j}$ is a random slope for the $\\beta_{1j}$ term, indicating that we are modeling cross country variation in these parameters. The other $\\beta$ terms are not modeled as having random country level variation, although this could certainly be a possibility in subsequent models. \n\nIn this formulation of the multilevel model, each regression parameter $\\beta$ in the level 1 equation is the outcome of an equation at Level 2. The parameters for the Level 2 equations are represented by $\\gamma$'s. $w$ a Level 2 variable appears in the first Level 2 equation.\n\n### One Level of Equations\n\nBy simply substituting the values of the Level 2 equations into the Level 1 equations--and rewriting the $\\gamma$'s as $\\beta$'s--we obtain:\n\n$$y_{ij} = \\beta_0 + \\beta_1 x_{ij} + \\beta_2 z_{ij} + \\beta_3 w_{j} + u_{0j} + u_{1j} \\times x + e_{ij}$$ {#eq-MLM}\n\nHere again $y_{ij}$ is the dependent variable, or outcome for the model. $\\beta_0$ is a regression intercept, and the $\\beta$'s are regression parameters. $x_{ij}$ and $z_{ij}$ are independent variables and $w$ is a Level 2 variable. \n\n> Notice that in this *single equation* format all variables--no matter their *level*--appear in the same equation. \n\nIn this formulation of the equation, the nature of the random effects is more clear, and merits discussion. Notice that we have included a *random intercept* $u_{0j}$ as well as a *random slope* $u_{1j} \\times x$. The *random intercept*, $u_{0j}$, indicates that there is variation in the *intercept* of the country specific regression lines, as is true in @fig-data. The *random slope* term associated with $x$, $u_{1j} \\times x$, indicates that we are allowing for the possibility of variation in the *slope* of the regression lines that is associated with $x$, in this case, the slope of parental warmth, as is possibly suggested in @fig-data. \n\n[^beta:]: Technically, all of these $\\beta$'s could be written as $\\beta_j$ since the multilevel model could be said to estimate a regression parameter for each group, in this case each country. One could even write $\\beta_{jk}$ to represent the regression parameter for the $k^{th}$ independent variable the for the $j^{th}$ group or country. To keep matters simple, I simply write $\\beta$ in most cases.\n\nTo make these ideas more concrete, I rewrite this equation in terms of the main substantive ideas of this document:\n\n$$\\text{outcome}_{ij} = \\beta_0 + \\beta_1 \\text{parental warmth}_{ij} + \\beta_2 \\text{physical punishment}_{ij} + \\beta_3 \\text{group}_{ij} + \\beta_4 \\text{HDI}_{j} \\ + $$ {#eq-MLMsubstantive}\n\n$$u_{0j} + u_{1j} \\times \\text{parental warmth} + e_{ij}$$\n\nPut substantively, this model indicates that the outcome can be conceptualized as a function of an intercept term, and contributions of parental warmth, physical punishment, group membership, and country level HDI. The random intercept, $u_{0j}$ indicates that there is some unexplained variation in the outcome at the country level. The random slope $u_{1j} \\times \\text{parental warmth}$ indicates that the model is allowing for country level variation in the association of parental warmth with the outcome. Inspection of @fig-data indicates that it might be possible that there would be variation across countries in this slope. The model could be extended to allow for country level variation in other slope terms by adding other random slopes, eg $u_{2j}$, $u_{3j}$, etc.\n\nDrawing upon ideas from @sec-software, this single level equation can be easily represented in Stata syntax.\n\n`mixed outcome warmth physical_punishment group HDI || country: warmth`\n\n\n## Regression With Simulated Multi-Country Data {#sec-regression}\n\nAfter considering some of these broader issues, let's now examine the results of a multilevel regression with the simulated multicountry data. I will again imagine that the desirable outcome is an outcome such as improved psychological wellbeing. \n\nThe Stata syntax that we use is:\n\n`mixed outcome warmth physical_punishment group HDI || country: warmth`\n\n\n\n\n\n|                     | cross_sectional |    |\n|---------------------|-----------------|----|\n| warmth              | 0.983           | ** |\n| physical_punishment | -0.924          | ** |\n| group               |                 |    |\n|   2                 | 0.728           | ** |\n| HDI                 | 0.008           |    |\n| _cons               | 51.500          | ** |\n| var(warmth)         | 0.000           |    |\n| var(_cons)          | 3.438           |    |\n| var(e)              | 34.784          |    |\n** p<.01, * p<.05\n\n\n\n\nThe data suggest that parental warmth is positively associated with the desirable outcome, and that this result is statistically significant. Parental use of physical punishment is associated with statistically significant decreases in the desirable outcome. I note that there is some variation in the *constant* indicating that there is some variation in the initial or average levels of the desirable outcome--again improved psychological well-being--that is attributable to country.\n\nThere is--in contrast--no discernible variation in the *slope* associated with parental warmth that is attributable to country. Thus, the relationship of parental warmth with child outcomes does not appear to differ appreciably from country to country. \n\n`HDI`, the *Human Development Index*, our only country level, or Level 2, variable in this model is not associated with the outcome.\n\n## Correlation of Random Intercept and Random Slope(s)\n\nOne could also consider a situation in which a random slope or slopes were correlated with each other, and with the random intercept. In the equation that we are considering, this would entail estimation of whether or not, the random intercept, $u_{0j}$, was correlated with the random slope for warmth, $u_{1j}$. \n\nSubstantively, this question would be asking whether the association of warmth and the outcome, was correlated with the initial level or average level of the outcome. From @fig-data, it appears that there is some slight evidence that the country specific regression slopes are more steep in countries where the initial level of the outcome is higher. However, we may wish to investigate this question more rigorously.\n\nBy default, Stata estimates models, where the random slope or slopes are uncorrelated with each other, and uncorrelated with the intercept [@StataCorp2021:2]. We see this in @eq-varcovar below, where the diagonal elements are the *variances* of each of the random effects, and the off diagonals, which would be the *covariances* of the random effects are constrained to 0.\n\n$$\\begin{bmatrix}\nvar(u_{0j}) & 0 \\\\\n0 & var(u_{1j}) \n\\end{bmatrix}$$ {#eq-varcovar}\n\nWithin Stata, we can ask to allow such a correlation with the `cov(uns)` option. \n\n$$\\begin{bmatrix}\nvar(u_{0j}) & cov(u_{0j}, u_{1j}) \\\\\ncov(u_{0j}, u_{1j}) & var(u_{1j}) \n\\end{bmatrix}$$ {#eq-varcovaruns}\n\nWe use the following syntax.\n\n`mixed outcome warmth physical_punishment group HDI || country: warmth, cov(uns)`\n\nWhen we estimate such a model, we get the following information.\n\n\n\n\n\n|                     | cross_sectional2 |    |\n|---------------------|------------------|----|\n| warmth              | 0.983            | ** |\n| physical_punishment | -0.926           | ** |\n| group               |                  |    |\n|   2                 | 0.727            | ** |\n| HDI                 | 0.007            |    |\n| _cons               | 51.523           | ** |\n| var(warmth)         | 0.002            |    |\n| var(_cons)          | 2.982            |    |\n| cov(warmth,_cons)   | 0.086            |    |\n| var(e)              | 34.769           |    |\n** p<.01, * p<.05\n\n\n\n\nResults are mostly similar to those above. However, here, we are asking additionally for information about the possible correlation of country specific initial levels of the outcome and the slope of the country specific regression line for parental warmth. Results indicate that there is no reason to be believe that these two parameters are correlated. Put more intuitively, it does not appear that parental warmth is any more or less correlated with the outcome in countries where initial levels of the outcome are higher. \n\n## Within and Between {#sec-withinbetween}\n\n\n\n\n::: {.cell}\n\n:::\n\n\n\n\nCoefficients in models can be divided into within and between. A substantive example may be helpful here. When we consider the variable of parental `warmth`, we can imagine the parental warmth expressed in each family, $\\text{warmth}_{ij}$, representing family *i* in country *j*. We can also think about the *grand mean* of warmth across the entire sample, $\\overline{\\text{warmth}}_{..}$. We can then also think about the mean expression of parental warmth in each country, $\\overline{\\text{warmth}}_{.j}$, i.e. the mean level of parental warmth in country *j*.\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Distribution of Parental Warmth Across Countries](cross-sectional_files/figure-pdf/fig-distributionwarmth-1.pdf){#fig-distributionwarmth}\n:::\n:::\n\n\n\n\nBearing this in mind, one can then think about the *difference* between each individual expression of parental warmth and the overall, or grand mean: $\\text{warmth}_{ij} - \\overline{\\text{warmth}}_{..}$. This value can then be decomposed into two values:\n\n$$\\text{warmth}_{ij} - \\overline{\\text{warmth}}_{..} = \\text{warmth}_{ij} - \\overline{\\text{warmth}}_{.j} + \\overline{\\text{warmth}}_{.j} - \\overline{\\text{warmth}}_{..}$$\nPut into words, this equation says that the difference in parental warmth displayed by family i in country j from the overall or grand mean of parental warmth is composed of two components:\n\n* *Within Country Component*: How is the level of warmth expressed by family *i* in country *j* different from the *mean* level of warmth in country *j*. Is family *i* different from the *average* family in country *j*? For this particular country, is this a family that is higher, or lower, than average in parental warmth?\n* *Between Country Component*: How is the *mean* level of warmth in country *j* different from the overall or *grand mean* level of warmth in the sample as a whole? To what degree is country *j* different from *all countries* in the sample? Is this country a country where parents tend to be higher, or lower, in parental warmth?\n\nTheoretically, or conceptually, one might imagine that it would be useful to decompose a particular behavior into within country and between country components. The within country component could be theorized as *how an individual family differs from their context*, and the between country component could be theorized as *how a particular context differs from the average context*. \n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Decomposing a Variable into Within and Between Differences](cross-sectional_files/figure-pdf/fig-withinbetween-1.pdf){#fig-withinbetween}\n:::\n:::\n\n\n\n\nIn terms of using statistical software (Stata), we need to follow a few steps.\n\n1. Calculate the *grand mean* of the variable.\n2. Calculate *country specific means* of the variable.\n3. Calculate:\n    + individual scores - country specific means\n    + country specific means - grand mean\n\n1. `egen gmean_warmth = mean(warmth)`\n2. `bysort country: egen cmean_warmth = mean(warmth)`\n3. `generate dev_warmth = warmth - cmean_warmth`\n4. `generate cdev_warmth = cmean_warmth - gmean_warmth`\n\n\n\n\n\n|                     | cross_sectional3 |    |\n|---------------------|------------------|----|\n| dev_warmth          | 0.980            | ** |\n| cdev_warmth         | 4.099            | ** |\n| physical_punishment | -0.924           | ** |\n| group               |                  |    |\n|   2                 | 0.729            | ** |\n| HDI                 | 0.013            |    |\n| _cons               | 53.667           | ** |\n| var(warmth)         | 0.000            |    |\n| var(_cons)          | 2.980            |    |\n| var(e)              | 34.784           |    |\n** p<.01, * p<.05\n\n\n\n\nEstimates suggest that both the difference in an individual family's expression of parental warmth from the country level mean, *and* the difference in the country level mean from the grand mean are statistically significant predictors of the outcome. The difference in the country level mean from the grand mean appears to have the larger effect.\n\n## Summary of Advantages Of The Multilevel Model\n\nThe discussion so far gives an idea of the advantages of the multilevel model for studying intrinsically multilevel data: children in classrooms or schools; individuals or families in neighborhoods; individuals or families in countries. These advantages can be summarized below:\n\n1. Standard errors are estimated correctly as is statistical significance. This means that p values are correctly estimated accounting for the clustered or nested nature of the data. More colloquially, this most often means that we do not make the mistake of attributing statistical significance to a given risk or protective factor, when such a statistical significance is not warranted. Put even more straightforwardly correct estimation of standard errors and statistical significance prevents us from seeing results that are simply not present in the data, whether those concern risk factors or protective factors. \n2. Regression coefficients are estimated correctly accounting for the clustered or nested structure of the data. If one does not account for the clustered or nested structure of the data, regression slopes can be estimated as negative when they are more correctly estimated as positive, or as null, or conversely estimated as positive when there are more correctly seen as negative (or null). Again, to phrase things in a more colloquial fashion, this means that we do not judge something to be a risk factor when it is in fact a protective factor or a null effect; or a protective factor when it is in fact a risk factor, or a null effect.  \n3. An increasing focus of statistical estimation is not to focus on particular regression parameters, but instead to predict outcomes for particular combinations of independent variables. Predictions from a multilevel model could be said to be best predictions in that groups are weighted by their precision, contributing to an estimate which makes better predictions than would a simple average. More colloquially, multilevel models allow us to predict outcomes better and more accurately than would be possible with simple or more naïve models.\n\n## Predicted Values\n\nAccording to **\"Stein's Paradox\"**, predictions from a multilevel model may be better than the mean.\n\n**shrinkage**\n\n## Variation\n\nAbove, in @sec-studyvariation, I have referred to multilevel models as the study of variation. Now that I have provided some discussion of the multilevel model, more statistical \"unpacking\" of ideas about variation is warranted. \n\nI provide again, for pedagogical purposes, the example substantive equation that I have been using in this document.\n\n$$\\text{outcome}_{ij} = \\beta_0 + \\beta_1 \\text{parental warmth}_{ij} + \\beta_2 \\text{physical punishment}_{ij} + \\beta_3 \\text{time}_{ij} \\ + $$ {#eq-MLMsubstantive2}\n\n$$u_{0j} + u_{1j} \\times \\text{parental warmth} + e_{ij}$$ \n\n### Measured and Unmeasured Variation\n\nThe first thing to note about the equation is that it can be divided into measured and unmeasured variation. \n\nThis is most easily seen if we introduce the idea of an unconditional model.\n\n### Unconditional Model\n\nThe unconditional model is a model with no $x$'s or covariates [@Raudenbush2002]. \n\n$$\\text{outcome}_{ij} = \\beta_0 + u_{0j} + e_{ij}$$ {#eq-unconditional}\n\nHere, $\\text{outcome}_{ij}$ is a function of an intercept $\\beta_0$, a country specific error term, $u_{0j}$, and an individual level error term $e_{ij}$.\n\nThus, all of the variation in $\\text{outcome}_{ij}$ is--given the unconditional nature of our model--due to unmeasured variation at the country and individual level.\n\n### Intra-Class Correlation Coefficient\n\nI now introduce a measure known as the Intra-Class Correlation Coefficient, (ICC) that can be computed from this unconditional model [@Raudenbush2002].\n\n$$\\text{ICC} = \\frac{var(u_{0j})}{var(u_{0j}) + var(e_{ij})}$$ {#eq-ICC}\n\nHeuristically:\n\n$$\\text{ICC} = \\frac{\\text{group level variation}}{\\text{group level variation} + \\text{individual level variation}}$$ {#eq-ICCheuristic}\n\nThe ICC from the *unconditional* model (@eq-unconditional) is the most informative ICC as it represents the amount of variation in the dependent variable that could *potentially* be explained by the grouping variable.\n\nAs we add covariates, $x$'s, to the model the ICC will most often decrease.\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Sources of Variation in a Multilevel Model](cross-sectional_files/figure-pdf/fig-variationsources-1.pdf){#fig-variationsources}\n:::\n:::\n\n\n\n \n### Variation In Intercepts or Outcomes\n\nIn @eq-MLMsubstantive2, $var(u_{0j})$ is the model estimated amount of variation in the *outcome*, $y_{ij}$.\n\nIn the regression in @sec-regression, there is discernible between country variation, but more of the variation is between individuals within the same country. Put another way, there is a moderate tendency for children in families in the same country to have similar outcomes, but two children in families in the same country may also have very different outcomes. Children from families in different countries may be as similar as children from families in the same country.\n\n### Variation In Predictors\n\nEqually important, I think, but much less frequently explored than variation in *outcomes*, is the possibility of variation in *predictors*. In the substantive example that we have employed so far, the *predictors* are different *parenting behaviors*, so considering variation in *predictors* allows us to consider variation in *parenting behaviors*, as well as variation in the *outcomes* of those behaviors.\n\nWe would estimate variation in behaviors in much the same way that we would estimate variation in outcomes, estimating an unconditional model, but substituting $x$ for $y$.\n\n$$x_{ij} = \\beta_0 + u_{0j} + e_{ij}$$ {#eq-unconditionalx}\n\nThen, similarly, the variation in a predictor attributable to the clustered nature of the data--in this case the clustering of individuals in countries--is given by:\n\n$$\\text{ICC}_x = \\frac{var(u_{0j})}{var(u_{0j}) + var(e_{ij})}$$ {#eq-ICCx}\n\n### Variation in Slopes\n\nAnother possible type of variation to investigate is variation in the relationship of $x$ and $y$, which is represented in the multilevel model by examining variation in the $\\beta$'s.\n\n### Variation As An Outcome\n\nEven less common is to examine *variation* itself as an outcome [@Burkner2018]. \n\n$$\\sigma_{yij} = \\beta_0 + \\beta_1 x_1 + u_{0j} + e_{ij}$$ {#eq-distributional}\n\nHere, the variation in the outcome, $\\sigma_{yij}$, rather than the mean level of the outcome, $y_{ij}$, is the focus of interest. My notation for @eq-distributional draws upon @Burkner2018's notation, but is modified in order to be consistent with the rest of this document. \n\nWhy might such models be of conceptual interest? Imagine for example, that the *variation* in psychological well-being is higher in countries with higher levels of poverty, or higher levels of income inequality. The use of such models as this, discussed in more detail by @Burkner2018, would allow us to explore such a question. \n\nOf note, while I do not explore in detail differences between Bayesian and frequentist approaches to multilevel modeling in this document, these models are likely to be only estimable with Bayesian software rather than with frequentist software [@Burkner2018]. \n\n### Maximal Models\n\nHypothetically, one might imagine that there could be group level unobserved factors which affect regression slopes—i.e. the relationship between a predictor x and outcome variable y—arguably, were one to ignore these unobserved factors in statistical estimation, they would show up either in an error term, or in the regression coefficients themselves. Were they to show up in the regression coefficients this would represent statistical bias and a substantive mis-estimation of important effects. thus, there is a conceptual argument for including as many random effects—i.e. random slopes—in a statistical model as possible.\n\nModels with all possible random effects are termed *maximal models* [@Barr2013; @Frank2018]. Such models include a large number of random slopes, e.g. $u_1 \\times x_1, u_2 \\times x_2, u_3 \\times x_3, ..., \\text{etc.}$ even when some of those estimated slopes are close to 0. Such models may be more easily estimable when using Bayesian estimation [@Frank2018], a topic which I do not cover in detail in this document. \n\nIt should be noted that @Matuschek2017 argue that such a *maximal* approach may lead to a loss of statistical power and further argue that one should adhere to \"a random effect structure that is supported by the data.\" In contrast, @nalborczyk_batailler_loevenbruck_vilain_burkner_2019 argue that maximal models are supported under the Bayesian approach. @Oberauer2022 also argues for including multiple random slopes. @Schielzeth2009 make a similar argument from a frequentist perspective.\n\n## Some Wrong (or Partially Wrong) Approaches {#sec-wrongapproaches}\n\nWhen data are clustered--e.g. residents in neighborhoods, children in schools, families in countries--it is worth discussing the fact that we have several choices statistically as how to proceed, other than using a multilevel model. Given the discussion so far, we can see the advantages of a multilevel model over these other approaches: \n\n1. First, we could simply ignore the clustering, and treat the data as though it were composed of statistically independent individuals, i.e. statistically independent $e_i$. As we have discussed above, however, this approach has at least two disadvantages. First, as discussed in @sec-pvalues, this approach will mis-estimate standard errors, most often underestimating them, resulting in underestimated p values and false positives. Second, as discussed in @sec-multilevelstructure ignoring clustering runs the risk of estimating regression $\\beta$'s that are not estimated with information about the multilevel structure of the data, with the possibility that $\\beta$ coefficients may not only have incorrect statistical significance, but also incorrect magnitude, and even incorrect sign.\n2. A second approach would be to *aggregate* the data to the level of the higher social unit, e.g. aggregating the data at the level of the neighborhood. Here we run into an idea similar to that discussed in @sec-multilevelstructure, the \"ecological fallacy\": the idea that group level and individual level relationships are necessarily the same [@FIREBAUGH20014023].\n3. Lastly, we could adopt a statistical strategy of *clustering* the standard errors. Clustering the standard errors means that standard errors are corrected for the non-independence of the $e_i$ within clusters. Thus, *p* values are estimated correctly. However, clustering still does not account for the multilevel structure of the data (@sec-multilevelstructure), and thus when relationships between *x*'s and *y* at different levels of the data are very different, simply clustering the standard errors may not give correct estimates of the $\\beta$'s.\n",
    "supporting": [
      "cross-sectional_files/figure-pdf"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {
      "knitr": [
        "{\"type\":\"list\",\"attributes\":{},\"value\":[]}"
      ]
    },
    "preserve": null,
    "postProcess": false
  }
}